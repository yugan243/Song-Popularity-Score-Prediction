{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Proprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from ../data/raw/train.csv\n",
      "Loading test data from ../data/raw/test.csv\n",
      "Train shape: (61609, 62)\n",
      "Test shape: (41074, 61)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.utils.utils import load_config\n",
    "from src.data.load_data import load_data\n",
    "\n",
    "config = load_config('../configs/config.yaml')\n",
    "train_df, test_df = load_data(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Impute using KNN and Mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 52 numerical columns and 9 categorical columns for imputation.\n",
      "\n",
      "[INFO] Starting KNN imputation for numerical features...\n",
      "[INFO] KNN imputation for numerical features completed in 641.62 seconds.\n",
      "\n",
      "[INFO] Starting mode imputation for categorical features...\n",
      "[INFO] Mode imputation for categorical features completed in 0.27 seconds.\n",
      "\n",
      "[INFO] Top columns with missing values in train after imputation:\n",
      "id                     0\n",
      "emotional_charge_2     0\n",
      "groove_efficiency_1    0\n",
      "beat_frequency_1       0\n",
      "organic_texture_2      0\n",
      "composition_label_0    0\n",
      "harmonic_scale_1       0\n",
      "intensity_index_0      0\n",
      "duration_ms_0          0\n",
      "album_name_length      0\n",
      "dtype: int64\n",
      "\n",
      "[INFO] Top columns with missing values in test after imputation:\n",
      "id                     0\n",
      "emotional_charge_2     0\n",
      "groove_efficiency_1    0\n",
      "beat_frequency_1       0\n",
      "organic_texture_2      0\n",
      "composition_label_0    0\n",
      "harmonic_scale_1       0\n",
      "intensity_index_0      0\n",
      "duration_ms_0          0\n",
      "album_name_length      0\n",
      "dtype: int64\n",
      "\n",
      "[INFO] Saving preprocessed datasets...\n",
      "[INFO] DataFrame saved to ../data/processed\\train_processed.csv\n",
      "[INFO] DataFrame saved to ../data/processed\\test_processed.csv\n",
      "[INFO] Preprocessed datasets saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "import time\n",
    "from src.utils.utils import load_config, save_dataframe\n",
    "import os\n",
    "\n",
    "# 1. Identify numerical and categorical columns\n",
    "num_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = train_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "if 'target' in num_cols:\n",
    "    num_cols.remove('target')\n",
    "\n",
    "print(f\"Identified {len(num_cols)} numerical columns and {len(cat_cols)} categorical columns for imputation.\")\n",
    "\n",
    "# 2. KNN Imputation for numerical columns\n",
    "print(\"\\n[INFO] Starting KNN imputation for numerical features...\")\n",
    "start_time = time.time()\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "train_df_imputed = train_df.copy()\n",
    "test_df_imputed = test_df.copy()\n",
    "\n",
    "train_df_imputed[num_cols] = imputer.fit_transform(train_df[num_cols])\n",
    "test_df_imputed[num_cols] = imputer.transform(test_df[num_cols])\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"[INFO] KNN imputation for numerical features completed in {elapsed:.2f} seconds.\")\n",
    "\n",
    "# 3. Mode imputation for categorical columns\n",
    "print(\"\\n[INFO] Starting mode imputation for categorical features...\")\n",
    "start_time = time.time()\n",
    "for col in cat_cols:\n",
    "    mode = train_df[col].mode()[0]\n",
    "    train_df_imputed[col] = train_df[col].fillna(mode)\n",
    "    test_df_imputed[col] = test_df[col].fillna(mode)\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"[INFO] Mode imputation for categorical features completed in {elapsed:.2f} seconds.\")\n",
    "\n",
    "# 4. Check missing values after imputation\n",
    "print(\"\\n[INFO] Top columns with missing values in train after imputation:\")\n",
    "print(train_df_imputed.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\n[INFO] Top columns with missing values in test after imputation:\")\n",
    "print(test_df_imputed.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "# 5. Save preprocessed data\n",
    "print(\"\\n[INFO] Saving preprocessed datasets...\")\n",
    "config = load_config('../configs/config.yaml')\n",
    "processed_dir = config['data']['processed_dir']\n",
    "\n",
    "# Define save paths\n",
    "train_save_path = os.path.join(processed_dir, \"train_processed.csv\")\n",
    "test_save_path = os.path.join(processed_dir, \"test_processed.csv\")\n",
    "\n",
    "# Save DataFrames\n",
    "save_dataframe(train_df_imputed, train_save_path)\n",
    "save_dataframe(test_df_imputed, test_save_path)\n",
    "\n",
    "print(\"[INFO] Preprocessed datasets saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scaling the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] DataFrame saved to ../data/processed\\train_standardized.csv\n",
      "[INFO] DataFrame saved to ../data/processed\\test_standardized.csv\n",
      "[INFO] Standardized datasets saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from src.data.preprocess import DataStandardizer\n",
    "from src.utils.utils import load_config, save_dataframe\n",
    "import os\n",
    "\n",
    "# 1. Initialize and fit on train\n",
    "standardizer = DataStandardizer()\n",
    "train_standardized = standardizer.fit_transform(train_df_imputed, target_col='target')\n",
    "test_standardized = standardizer.transform(test_df_imputed)\n",
    "\n",
    "# 2. Save standardized data\n",
    "config = load_config('../configs/config.yaml')\n",
    "processed_dir = config['data']['processed_dir']\n",
    "train_save_path = os.path.join(processed_dir, \"train_standardized.csv\")\n",
    "test_save_path = os.path.join(processed_dir, \"test_standardized.csv\")\n",
    "\n",
    "save_dataframe(train_standardized, train_save_path)\n",
    "save_dataframe(test_standardized, test_save_path)\n",
    "\n",
    "print(\"[INFO] Standardized datasets saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
